{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Factuality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('factuality_predictions_with_alexa.csv')\n",
    "\n",
    "df_test['alexa_rank_quartile'] = pd.qcut(df_test['alexa_rank'], 4, labels=[\"Q1 (Most Popular)\", \"Q2\", \"Q3\", \"Q4 (Least Popular)\"])\n",
    "\n",
    "# Calculate accuracy per quartile\n",
    "df_test['correct_prediction'] = df_test['factuality'] == df_test['predicted_factuality']\n",
    "accuracy_by_quartile = df_test.groupby('alexa_rank_quartile')['correct_prediction'].mean()\n",
    "\n",
    "# Bar plot of accuracy by quartile\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=accuracy_by_quartile.index, y=accuracy_by_quartile.values)\n",
    "plt.title(\"Prediction Accuracy by Media Popularity Quartile\")\n",
    "plt.xlabel(\"Alexa Rank Quartile\")\n",
    "plt.ylabel(\"Prediction Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Political Bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_bias = pd.read_csv('bias_predictions_with_alexa.csv')\n",
    "\n",
    "# Create quartiles for Alexa Rank\n",
    "df_test_bias['alexa_rank_quartile'] = pd.qcut(df_test_bias['alexa_rank'], 4, labels=[\"Q1 (Most Popular)\", \"Q2\", \"Q3\", \"Q4 (Least Popular)\"])\n",
    "\n",
    "# Calculate accuracy per quartile\n",
    "df_test_bias['correct_prediction'] = df_test_bias['bias_label_3_class'] == df_test_bias['predicted_bias']\n",
    "accuracy_by_quartile = df_test_bias.groupby('alexa_rank_quartile')['correct_prediction'].mean()\n",
    "\n",
    "# Bar plot of accuracy by quartile\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=accuracy_by_quartile.index, y=accuracy_by_quartile.values)\n",
    "plt.title(\"Prediction Accuracy by Media Popularity Quartile\")\n",
    "plt.xlabel(\"Alexa Rank Quartile\")\n",
    "plt.ylabel(\"Prediction Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Media Popularity: Bias & Factuality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_test_factuality = pd.read_csv('factuality_predictions_with_alexa.csv')\n",
    "df_test_bias = pd.read_csv('bias_predictions_with_alexa.csv')\n",
    "\n",
    "# Factuality plot mappings\n",
    "factuality_mapping = {'LOW': 0, 'MIXED': 1, 'HIGH': 2}\n",
    "df_test_factuality['factuality_num'] = df_test_factuality['factuality'].map(factuality_mapping)\n",
    "factuality_marker_styles = {'LOW': '.', 'MIXED': 'x', 'HIGH': '*'}\n",
    "factuality_manual_order = ['Low - Correct', 'Low - Incorrect', 'Mixed - Correct', 'Mixed - Incorrect', 'High - Correct', 'High - Incorrect']\n",
    "\n",
    "# Political bias plot mappings\n",
    "bias_mapping = {'left': 0, 'center': 1, 'right': 2}\n",
    "df_test_bias['bias_num'] = df_test_bias['bias_label_3_class'].map(bias_mapping)\n",
    "bias_marker_styles = {'left': '.', 'center': 'x', 'right': '*'}\n",
    "bias_manual_order = ['Left - Correct', 'Left - Incorrect', 'Center - Correct', 'Center - Incorrect', 'Right - Correct', 'Right - Incorrect']\n",
    "\n",
    "# Add jitter\n",
    "factuality_jitter = np.random.uniform(-0.1, 0.1, size=len(df_test_factuality))\n",
    "bias_jitter = np.random.uniform(-0.1, 0.1, size=len(df_test_bias))\n",
    "\n",
    "# Create the combined figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))  # Two plots side-by-side\n",
    "\n",
    "### Political Bias Plot ###\n",
    "for _, row in df_test_bias.iterrows():\n",
    "    x = row['bias_num'] + bias_jitter[_]\n",
    "    y = row['alexa_rank']\n",
    "    predicted = row['predicted_bias']\n",
    "    marker = bias_marker_styles[row['bias_label_3_class']]\n",
    "    color = 'green' if row['bias_label_3_class'] == predicted else 'red'\n",
    "    axes[0].scatter(x, y, marker=marker, color=color, s=75,\n",
    "                    label=f\"{row['bias_label_3_class'].capitalize()} - Correct\" if color == 'green' else f\"{row['bias_label_3_class'].capitalize()} - Incorrect\")\n",
    "\n",
    "axes[0].set_xticks(list(bias_mapping.values()))\n",
    "axes[0].set_xticklabels(['Left', 'Center', 'Right'])\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Political Bias Labels')\n",
    "axes[0].set_ylabel('Alexa Rank (Log Scale)')\n",
    "axes[0].set_title('(a) Political Bias vs. Alexa Rank')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Legend for bias\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # Avoid duplicates\n",
    "axes[0].legend([by_label[label] for label in bias_manual_order], bias_manual_order, loc='lower left')\n",
    "\n",
    "### Factuality Plot ###\n",
    "for _, row in df_test_factuality.iterrows():\n",
    "    x = row['factuality_num'] + factuality_jitter[_]\n",
    "    y = row['alexa_rank']\n",
    "    predicted = row['predicted_factuality']\n",
    "    marker = factuality_marker_styles[row['factuality']]\n",
    "    color = 'green' if row['factuality'] == predicted else 'red'\n",
    "    axes[1].scatter(x, y, marker=marker, color=color, s=75,\n",
    "                    label=f\"{row['factuality'].capitalize()} - Correct\" if color == 'green' else f\"{row['factuality'].capitalize()} - Incorrect\")\n",
    "\n",
    "axes[1].set_xticks(list(factuality_mapping.values()))\n",
    "axes[1].set_xticklabels(['Low', 'Mixed', 'High'])\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Factuality Labels')\n",
    "axes[1].set_ylabel('Alexa Rank (Log Scale)')\n",
    "axes[1].set_title('(b) Factuality vs. Alexa Rank')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Legend for factuality\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # Avoid duplicates\n",
    "axes[1].legend([by_label[label] for label in factuality_manual_order], factuality_manual_order, loc='lower right')\n",
    "\n",
    "# Adjust layout and save the combined figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('side_by_side_bias_factuality_with_labels.png', dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
